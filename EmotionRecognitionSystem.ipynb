{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1edd015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asa\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "webcam_active = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9e0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_webcam():\n",
    "    global webcam_active\n",
    "    webcam_active = True\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while webcam_active:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        result = None\n",
    "        try:\n",
    "            result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        except Exception as e:\n",
    "            print(f\"DeepFace analysis error: {e}\")\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        if result is not None:\n",
    "            dominant_emotion = result[0]['dominant_emotion']\n",
    "            cv2.putText(frame, dominant_emotion, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_4)\n",
    "\n",
    "        cv2.imshow('Webcam Video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f379af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_webcam_thread():\n",
    "    webcam_thread = threading.Thread(target=analyze_webcam)\n",
    "    webcam_thread.start()\n",
    "\n",
    "def stop_webcam():\n",
    "    global webcam_active\n",
    "    webcam_active = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12133319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, max_width, max_height):\n",
    "    # Calculate the ratio of the width and height\n",
    "    width_ratio = max_width / image.width\n",
    "    height_ratio = max_height / image.height\n",
    "    # Use the smallest ratio to resize the image\n",
    "    ratio = min(width_ratio, height_ratio)\n",
    "    new_width = int(image.width * ratio)\n",
    "    new_height = int(image.height * ratio)\n",
    "    return image.resize((new_width, new_height), Image.LANCZOS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4a824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file():\n",
    "    global panel, emotion_label\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    if panel is not None:\n",
    "        panel.pack_forget()\n",
    "    if emotion_label is not None:\n",
    "        emotion_label.config(text=\"\")\n",
    "\n",
    "    if file_path.endswith(('.mp4', '.avi', '.mov')):\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            result = None\n",
    "            try:\n",
    "                result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "            except Exception as e:\n",
    "                print(f\"DeepFace analysis error: {e}\")\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            if result is not None:\n",
    "                dominant_emotion = result[0]['dominant_emotion']\n",
    "                cv2.putText(frame, dominant_emotion, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_4)\n",
    "\n",
    "            cv2.imshow('Video File', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        frame = cv2.imread(file_path)\n",
    "        result = None\n",
    "        try:\n",
    "            result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "        except Exception as e:\n",
    "            print(f\"DeepFace analysis error: {e}\")\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        if result is not None:\n",
    "            dominant_emotion = result[0]['dominant_emotion']\n",
    "            emotion_label.config(text=f\"Dominant Emotion: {dominant_emotion}\")\n",
    "\n",
    "        # Resize the image to fit the GUI window\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        img = resize_image(img, 800, 600)  # Resize to fit window\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        panel.config(image=img_tk)\n",
    "        panel.image = img_tk\n",
    "        panel.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c69c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Emotion Analyzer\")\n",
    "root.geometry(\"1000x800\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure('TButton', font=('Helvetica', 12), padding=10)\n",
    "\n",
    "panel = tk.Label(root, bg=\"#f0f0f0\")\n",
    "panel.pack(pady=10)\n",
    "\n",
    "emotion_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 16), bg=\"#f0f0f0\")\n",
    "emotion_label.pack(pady=10)\n",
    "\n",
    "\n",
    "button_frame = tk.Frame(root, bg=\"#f0f0f0\")\n",
    "button_frame.pack(pady=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_webcam = ttk.Button(button_frame, text=\"Analyze from Webcam\", command=start_webcam_thread)\n",
    "btn_webcam.grid(row=0, column=0, padx=10)\n",
    "\n",
    "btn_stop_webcam = ttk.Button(button_frame, text=\"Stop Webcam\", command=stop_webcam)\n",
    "btn_stop_webcam.grid(row=0, column=1, padx=10)\n",
    "\n",
    "btn_file = ttk.Button(button_frame, text=\"Analyze from File\", command=analyze_file)\n",
    "btn_file.grid(row=0, column=2, padx=10)\n",
    "\n",
    "import threading\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d4057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bd09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd2050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
